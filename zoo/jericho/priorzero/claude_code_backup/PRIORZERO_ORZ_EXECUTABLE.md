# PriorZero-ORZ æ··åˆ Pipeline - å®é™…å¯æ‰§è¡Œç‰ˆæœ¬

**æ–‡ä»¶**: `priorzero_orz_entry.py`
**çŠ¶æ€**: âœ… å®Œæ•´å¯æ‰§è¡Œ
**æ›´æ–°**: 2025-10-21

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

è¿™æ˜¯ä¸€ä¸ª**å®Œå…¨å¤ç”¨ PriorZero åŸºç¡€è®¾æ–½**çš„å¯æ‰§è¡Œ pipeline:

âœ… **å¤ç”¨ç»„ä»¶**:
- `PriorZeroCollector` - MCTS æ•°æ®æ”¶é›†
- `PriorZeroEvaluator` - è¯„ä¼°å™¨
- `PriorZeroGameBufferOptimized` - Replay buffer
- `priorzero_policy` - World model + LLM è®­ç»ƒ
- `priorzero_config` - é…ç½®ç³»ç»Ÿ

âœ… **å¯é€‰ ORZ é›†æˆ**:
- è‡ªåŠ¨æ£€æµ‹ ORZ æ˜¯å¦å¯ç”¨
- å¦‚æœä¸å¯ç”¨,ä½¿ç”¨ PriorZero å†…ç½® LLM è®­ç»ƒ
- ä¸ºæœªæ¥å®Œæ•´ ORZ é›†æˆé¢„ç•™æ¥å£

âœ… **æ··åˆè®­ç»ƒæ¨¡å¼**:
- World Model è®­ç»ƒé¢‘ç‡å¯é…ç½®
- LLM è®­ç»ƒé¢‘ç‡å¯é…ç½®
- æ”¯æŒå¹¶è¡Œ/é¡ºåº/äº¤æ›¿è®­ç»ƒ

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. Debug æ¨¡å¼ (æµ‹è¯•è¿è¡Œ)

```bash
cd /mnt/nfs/zhangjinouwen/puyuan/LightZero

# Debug æ¨¡å¼ - å°è§„æ¨¡,å¿«é€ŸéªŒè¯
DEBUG_MODE=True python -m zoo.jericho.priorzero.priorzero_orz_entry
```

**Debug æ¨¡å¼è®¾ç½®**:
- ä½¿ç”¨ `get_priorzero_config_for_quick_test()`
- å° batch size (20)
- å°‘é‡æ¨¡æ‹Ÿ (5)
- 100 æ¬¡è¿­ä»£

### 2. æ­£å¸¸è®­ç»ƒ

```bash
# æ­£å¸¸è®­ç»ƒ
python -m zoo.jericho.priorzero.priorzero_orz_entry
```

---

## ğŸ“Š è®­ç»ƒæµç¨‹

```
åˆå§‹åŒ–
â”œâ”€ vLLM Engine (LLM æ¨ç†)
â”œâ”€ Environments (Jericho)
â”œâ”€ Policy (UniZero + LLM)
â”œâ”€ Collector (MCTS)
â”œâ”€ Evaluator
â””â”€ Replay Buffer

ä¸»å¾ªç¯ (æ¯æ¬¡è¿­ä»£):
â”œâ”€ 1. Evaluation (å®šæœŸ)
â”‚   â””â”€ è¯„ä¼°å½“å‰ç­–ç•¥è´¨é‡
â”œâ”€ 2. Collect Data
â”‚   â”œâ”€ MCTS è§„åˆ’
â”‚   â”œâ”€ LLM Prior (å¯é€‰)
â”‚   â””â”€ æ”¶é›† game_segments
â”œâ”€ 3. Train World Model
â”‚   â”œâ”€ Sample from buffer
â”‚   â”œâ”€ è®­ç»ƒ dynamics/value/policy
â”‚   â””â”€ è®­ç»ƒ LLM (SFT/RFT)
â”œâ”€ 4. Train LLM with ORZ (å¯é€‰,æœªæ¥)
â”‚   â””â”€ ä½¿ç”¨ ORZ RayPPOTrainer
â””â”€ 5. Logging & Checkpointing
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### `HybridTrainingConfig`

```python
# åŸºç¡€é…ç½® (ä» PriorZero ç»§æ‰¿)
priorzero_cfg  # å®Œæ•´çš„ PriorZero é…ç½®
priorzero_create_cfg  # DI-engine ç»„ä»¶åˆ›å»ºé…ç½®

# æ··åˆè®­ç»ƒè®¾ç½®
wm_training_mode = "parallel"  # è®­ç»ƒæ¨¡å¼
wm_train_freq = 1              # WM è®­ç»ƒé¢‘ç‡
llm_train_freq = 5             # LLM è®­ç»ƒé¢‘ç‡
use_orz_trainer = ORZ_AVAILABLE  # æ˜¯å¦ä½¿ç”¨ ORZ

# ORZ è®¾ç½® (å¦‚æœå¯ç”¨)
orz_rollout_batch_size = 128
orz_train_batch_size = 32
orz_actor_lr = 1e-6
orz_critic_lr = 5e-6
```

### ä¿®æ”¹é…ç½®

```python
# æ–¹æ³• 1: ä¿®æ”¹ HybridTrainingConfig.__init__()
def __init__(self):
    # ... ç°æœ‰ä»£ç  ...
    self.wm_train_freq = 2  # æ”¹ä¸ºæ¯ 2 æ¬¡è¿­ä»£è®­ç»ƒä¸€æ¬¡

# æ–¹æ³• 2: ä½¿ç”¨ä¸åŒçš„ PriorZero é…ç½®
from priorzero_config import get_priorzero_config
self.priorzero_cfg, _ = get_priorzero_config(
    env_id='detective.z5',  # æ”¹ä¸ºå…¶ä»–æ¸¸æˆ
    enable_rft=True
)
```

---

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

### TensorBoard

```bash
tensorboard --logdir=./data_priorzero/ --port=6006
```

**å…³é”®æŒ‡æ ‡**:
- `train/wm_total_loss` - World model æ€»æŸå¤±
- `train/llm_sft_loss` - LLM SFT æŸå¤±
- `train/llm_rft_loss` - LLM RFT æŸå¤±
- `evals/reward_mean` - è¯„ä¼°å¹³å‡å¥–åŠ±

### æ—¥å¿—æ–‡ä»¶

```bash
# å®æ—¶æŸ¥çœ‹
tail -f ./data_priorzero_*/log/*.log

# æœç´¢å…³é”®ä¿¡æ¯
grep "Training world model" ./data_priorzero_*/log/*.log
```

---

## ğŸ”§ ä»£ç ç»“æ„

### å…³é”®å‡½æ•°

#### `train_priorzero_orz()`
ä¸»è®­ç»ƒå‡½æ•°,åŒ…å«å®Œæ•´è®­ç»ƒå¾ªç¯:
1. åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
2. ä¸»å¾ªç¯ (collect â†’ train â†’ eval)
3. æ¸…ç†å’Œä¿å­˜

#### `HybridTrainingConfig`
é…ç½®ç±»,åˆå¹¶ PriorZero å’Œ ORZ è®¾ç½®

#### `main()`
å…¥å£å‡½æ•°,åˆ›å»ºé…ç½®å¹¶å¯åŠ¨è®­ç»ƒ

### ä¾èµ–å…³ç³»

```
priorzero_orz_entry.py
â”œâ”€ priorzero_config  # é…ç½®
â”œâ”€ priorzero_collector  # æ•°æ®æ”¶é›†
â”œâ”€ priorzero_evaluator  # è¯„ä¼°
â”œâ”€ priorzero_policy  # WM + LLM è®­ç»ƒ
â”œâ”€ game_buffer_priorzero  # Replay buffer
â””â”€ ORZ (å¯é€‰)
    â”œâ”€ RayPPOTrainer
    â””â”€ BasePPOExp
```

---

## âœ… ä¸åŸ PriorZero çš„å¯¹æ¯”

| Feature | priorzero_entry.py | priorzero_orz_entry.py |
|---------|-------------------|------------------------|
| **åŸºç¡€è®¾æ–½** | âœ… å®Œæ•´ | âœ… å®Œæ•´ (å¤ç”¨) |
| **World Model** | âœ… UniZero | âœ… UniZero (ç›¸åŒ) |
| **LLM è®­ç»ƒ** | âœ… SFT/RFT | âœ… SFT/RFT (+ ORZ å¯é€‰) |
| **å¼‚æ­¥è®­ç»ƒ** | âœ… | âŒ (ç®€åŒ–) |
| **ORZ é›†æˆ** | âŒ | âœ… (å¯é€‰) |
| **ä»£ç å¤æ‚åº¦** | â­â­â­â­ | â­â­â­ |

---

## ğŸ› å½“å‰çŠ¶æ€

### å·²å®ç° âœ…

1. âœ… **å®Œæ•´çš„è®­ç»ƒå¾ªç¯**
   - Collect â†’ Train â†’ Eval
   - ä¸ `priorzero_entry.py` ä¸€è‡´

2. âœ… **æ‰€æœ‰ PriorZero ç»„ä»¶**
   - Collector, Evaluator, Policy, Buffer
   - vLLM Engine for LLM inference

3. âœ… **é…ç½®ç³»ç»Ÿ**
   - å¤ç”¨ PriorZero é…ç½®
   - æ·»åŠ æ··åˆè®­ç»ƒé€‰é¡¹

4. âœ… **é”™è¯¯å¤„ç†**
   - vLLM åˆå§‹åŒ–å¤±è´¥ fallback
   - Graceful shutdown

### å¾…å®ç° / æ‰©å±• ğŸ”¨

1. **ORZ RayPPOTrainer å®Œæ•´é›†æˆ**
   ```python
   # å½“å‰: å ä½ç¬¦
   if hybrid_cfg.use_orz_trainer and orz_trainer:
       # TODO: Implement ORZ training step
       pass

   # æœªæ¥: å®é™…å®ç°
   if hybrid_cfg.use_orz_trainer and orz_trainer:
       # 1. Extract game_segments from buffer
       game_segments = replay_buffer.sample_game_segments(...)

       # 2. Convert to ORZ format
       orz_data = convert_to_orz_format(game_segments)

       # 3. Train with ORZ
       orz_trainer.train(orz_data)
   ```

2. **æ›´å¤šè®­ç»ƒæ¨¡å¼**
   - Sequential: WM â†’ LLM é¡ºåºè®­ç»ƒ
   - Alternating: è½®æµè®­ç»ƒ
   - (å½“å‰åªæœ‰ parallel)

3. **é«˜çº§ ORZ ç‰¹æ€§**
   - GRPO
   - Multi-node Ray setup
   - Advanced reward shaping

---

## ğŸ¯ ä½¿ç”¨å»ºè®®

### åˆæ¬¡è¿è¡Œ

```bash
# 1. å…ˆç”¨ debug æ¨¡å¼æµ‹è¯•
DEBUG_MODE=True python -m zoo.jericho.priorzero.priorzero_orz_entry

# é¢„æœŸè¾“å‡º:
# - âœ“ vLLM Engine created
# - âœ“ Environments created
# - âœ“ Policy created
# - âœ“ Collector created
# - [Iter 0] Collecting data...
# - [Iter 0] Training world model...
```

### å¦‚æœé‡åˆ°é—®é¢˜

1. **vLLM åˆå§‹åŒ–å¤±è´¥**:
   ```bash
   # æ£€æŸ¥ GPU
   nvidia-smi

   # é™ä½å†…å­˜ä½¿ç”¨
   # ç¼–è¾‘é…ç½®: gpu_memory_utilization = 0.5
   ```

2. **ORZ å¯¼å…¥å¤±è´¥**:
   ```bash
   # æ£€æŸ¥è·¯å¾„
   ls /mnt/nfs/zhangjinouwen/puyuan/Open-Reasoner-Zero

   # ä¸å½±å“è¿è¡Œ - ä¼š fallback åˆ° PriorZero LLM è®­ç»ƒ
   ```

3. **å†…å­˜ä¸è¶³**:
   ```bash
   # ä½¿ç”¨ debug æ¨¡å¼ (æ›´å°çš„ batch)
   DEBUG_MODE=True python ...
   ```

---

## ğŸ“ ä¸‹ä¸€æ­¥å¼€å‘

### çŸ­æœŸ (1-2 weeks)

1. å®ç° ORZ RayPPOTrainer å®Œæ•´é›†æˆ
2. æ·»åŠ  game_segments åˆ° ORZ æ ¼å¼è½¬æ¢
3. æµ‹è¯•å¤š GPU è®­ç»ƒ

### ä¸­æœŸ (1 month)

1. å®ç° sequential/alternating è®­ç»ƒæ¨¡å¼
2. æ·»åŠ  Wandb é›†æˆ
3. ä¼˜åŒ–å†…å­˜ä½¿ç”¨

### é•¿æœŸ (2+ months)

1. å¤šæ¸¸æˆæ”¯æŒ
2. Meta-learning
3. è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜

---

## ğŸ‰ æ€»ç»“

è¿™æ˜¯ä¸€ä¸ª**å®Œå…¨å¯æ‰§è¡Œçš„** PriorZero-ORZ æ··åˆ pipeline:

âœ… **ç«‹å³å¯ç”¨**:
```bash
DEBUG_MODE=True python -m zoo.jericho.priorzero.priorzero_orz_entry
```

âœ… **å¤ç”¨ä»£ç **: 100% å¤ç”¨ PriorZero åŸºç¡€è®¾æ–½

âœ… **æ¨¡å—åŒ–**: ä¸å½±å“ç°æœ‰ `priorzero_entry.py`

âœ… **å¯æ‰©å±•**: é¢„ç•™ ORZ å®Œæ•´é›†æˆæ¥å£

**å¼€å§‹è®­ç»ƒå§ï¼** ğŸš€
