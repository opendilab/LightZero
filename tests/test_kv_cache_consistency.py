"""
KV Cache é‡æ„å‰åä¸€è‡´æ€§æµ‹è¯•
=========================

æµ‹è¯•æ–°æ—§ KV Cache ç³»ç»Ÿçš„è¡Œä¸ºä¸€è‡´æ€§ã€‚
åŸºäºç®€åŒ–çš„ atari_unizero_segment_configã€‚

è¿è¡Œæ–¹å¼:
    cd /mnt/nfs/zhangjinouwen/puyuan/LightZero
    conda activate /mnt/nfs/zhangjinouwen/puyuan/conda_envs/lz
    python tests/test_kv_cache_consistency.py
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import torch
import numpy as np
from easydict import EasyDict


def create_minimal_config(use_new_cache=False):
    """åˆ›å»ºæœ€å°åŒ–çš„é…ç½®ç”¨äºæµ‹è¯•"""
    from lzero.model.unizero_world_models.transformer import TransformerConfig

    config = TransformerConfig(
        # Required TransformerConfig parameters
        tokens_per_block=2,
        max_blocks=10,
        attention='causal',
        num_layers=2,
        num_heads=8,
        embed_dim=768,
        embed_pdrop=0.1,
        resid_pdrop=0.1,
        attn_pdrop=0.1,
        task_embed_option='none',
    )

    # Add additional attributes needed by WorldModel
    config.env_num = 4
    config.game_segment_length = 20
    config.num_simulations = 25
    config.action_space_size = 6
    config.observation_shape = (3, 64, 64)
    config.image_channel = 3
    config.support_size = 601
    config.obs_type = 'image'
    config.device = 'cuda' if torch.cuda.is_available() else 'cpu'
    config.continuous_action_space = False
    config.group_size = 8
    config.norm_type = 'LN'
    config.rotary_emb = False
    config.context_length = 8

    # Additional config parameters required by _initialize_config_parameters
    config.policy_entropy_weight = 0.0
    config.predict_latent_loss_type = 'smooth_l1'
    config.gamma = 0.997
    config.dormant_threshold = 0.025
    config.analysis_dormant_ratio_weight_rank = False
    config.latent_recon_loss_weight = 0.0
    config.perceptual_loss_weight = 0.0
    config.max_cache_size = 2000

    # KV Cache setting - âœ¨ å…³é”®é…ç½®
    config.use_new_cache_manager = use_new_cache

    return config


def test_initialization():
    """æµ‹è¯•åˆå§‹åŒ–"""
    print("\n" + "="*70)
    print("æµ‹è¯• 1: åˆå§‹åŒ–å¯¹æ¯”")
    print("="*70)

    from lzero.model.unizero_world_models.world_model import WorldModel
    from unittest.mock import Mock, MagicMock

    # åˆ›å»ºä¸€ä¸ªæ›´å®Œæ•´çš„ mock tokenizer
    # WorldModel éœ€è¦ tokenizer æœ‰ä»¥ä¸‹å±æ€§:
    # - embed_dim: int
    # - encoder.pretrained_model (å¯èƒ½ä¸å­˜åœ¨,éœ€è¦ç”¨ hasattr æ£€æŸ¥)
    # - decoder_network (å¯èƒ½ä¸å­˜åœ¨,éœ€è¦ç”¨ hasattr æ£€æŸ¥)

    class SimpleTokenizer:
        def __init__(self):
            self.embed_dim = 768
            self.encoder = None  # æ²¡æœ‰ encoder,é¿å… hasattr æ£€æŸ¥å¤±è´¥
            self.decoder_network = None

    mock_tokenizer = SimpleTokenizer()

    # æµ‹è¯•æ—§ç³»ç»Ÿ
    print("\n[æ—§ç³»ç»Ÿ] åˆå§‹åŒ–...")
    config_old = create_minimal_config(use_new_cache=False)
    model_old = WorldModel(config_old, mock_tokenizer)

    assert hasattr(model_old, 'use_new_cache_manager')
    assert model_old.use_new_cache_manager == False
    assert hasattr(model_old, 'past_kv_cache_init_infer_envs')
    assert hasattr(model_old, 'past_kv_cache_recurrent_infer')
    print("âœ“ æ—§ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
    print(f"  - use_new_cache_manager: {model_old.use_new_cache_manager}")
    print(f"  - past_kv_cache_init_infer_envs: {len(model_old.past_kv_cache_init_infer_envs)} envs")

    # æµ‹è¯•æ–°ç³»ç»Ÿ
    print("\n[æ–°ç³»ç»Ÿ] åˆå§‹åŒ–...")
    config_new = create_minimal_config(use_new_cache=True)
    model_new = WorldModel(config_new, mock_tokenizer)

    assert hasattr(model_new, 'use_new_cache_manager')
    assert model_new.use_new_cache_manager == True
    assert hasattr(model_new, 'kv_cache_manager')
    print("âœ“ æ–°ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
    print(f"  - use_new_cache_manager: {model_new.use_new_cache_manager}")
    print(f"  - kv_cache_manager: {type(model_new.kv_cache_manager)}")
    print(f"  - init_pools: {len(model_new.kv_cache_manager.init_pools)} pools")

    # éªŒè¯å‘åå…¼å®¹
    assert hasattr(model_new, 'keys_values_wm_list')
    assert hasattr(model_new, 'keys_values_wm_size_list')
    print("âœ“ å‘åå…¼å®¹æ€§éªŒè¯é€šè¿‡")

    print("\nâœ… æµ‹è¯• 1 é€šè¿‡: ä¸¤ä¸ªç³»ç»Ÿéƒ½èƒ½æ­£ç¡®åˆå§‹åŒ–\n")

    return model_old, model_new


def test_cache_structures():
    """æµ‹è¯• cache æ•°æ®ç»“æ„"""
    print("\n" + "="*70)
    print("æµ‹è¯• 2: Cache æ•°æ®ç»“æ„å¯¹æ¯”")
    print("="*70)

    model_old, model_new = test_initialization()

    # æ—§ç³»ç»Ÿçš„æ•°æ®ç»“æ„
    print("\n[æ—§ç³»ç»Ÿ] Cache ç»“æ„:")
    print(f"  - past_kv_cache_init_infer_envs: {type(model_old.past_kv_cache_init_infer_envs)}")
    print(f"    Length: {len(model_old.past_kv_cache_init_infer_envs)}")
    print(f"  - past_kv_cache_recurrent_infer: {type(model_old.past_kv_cache_recurrent_infer)}")
    print(f"  - keys_values_wm_list: {type(model_old.keys_values_wm_list)}")

    # æ–°ç³»ç»Ÿçš„æ•°æ®ç»“æ„
    print("\n[æ–°ç³»ç»Ÿ] Cache ç»“æ„:")
    print(f"  - kv_cache_manager: {type(model_new.kv_cache_manager)}")
    print(f"    init_pools: {len(model_new.kv_cache_manager.init_pools)} pools")
    print(f"    recur_pool: {type(model_new.kv_cache_manager.recur_pool)}")
    print(f"    wm_pool: {type(model_new.kv_cache_manager.wm_pool)}")
    print(f"  - keys_values_wm_list (compat): {type(model_new.keys_values_wm_list)}")

    # éªŒè¯ç¯å¢ƒæ•°é‡ä¸€è‡´
    assert len(model_old.past_kv_cache_init_infer_envs) == len(model_new.kv_cache_manager.init_pools)
    print("\nâœ“ ç¯å¢ƒæ•°é‡ä¸€è‡´")

    print("\nâœ… æµ‹è¯• 2 é€šè¿‡: Cache ç»“æ„æ­£ç¡®\n")


def test_clear_caches():
    """æµ‹è¯• clear_caches æ–¹æ³•"""
    print("\n" + "="*70)
    print("æµ‹è¯• 3: clear_caches() æ–¹æ³•å¯¹æ¯”")
    print("="*70)

    model_old, model_new = test_initialization()

    # æµ‹è¯•æ—§ç³»ç»Ÿ
    print("\n[æ—§ç³»ç»Ÿ] clear_caches()...")
    try:
        model_old.clear_caches()
        print("âœ“ æ—§ç³»ç»Ÿ clear_caches() æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ—§ç³»ç»Ÿ clear_caches() å¤±è´¥: {e}")
        raise

    # æµ‹è¯•æ–°ç³»ç»Ÿ
    print("\n[æ–°ç³»ç»Ÿ] clear_caches()...")
    try:
        model_new.clear_caches()
        print("âœ“ æ–°ç³»ç»Ÿ clear_caches() æˆåŠŸ")

        # éªŒè¯æ¸…é™¤æˆåŠŸ
        assert len(model_new.kv_cache_manager.init_pools[0]) == 0
        print("âœ“ éªŒè¯: cache å·²æ¸…ç©º")
    except Exception as e:
        print(f"âŒ æ–°ç³»ç»Ÿ clear_caches() å¤±è´¥: {e}")
        raise

    print("\nâœ… æµ‹è¯• 3 é€šè¿‡: clear_caches() æ–¹æ³•å·¥ä½œæ­£å¸¸\n")


def test_model_forward():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­ (ç®€åŒ–ç‰ˆ)"""
    print("\n" + "="*70)
    print("æµ‹è¯• 4: æ¨¡å‹ç»“æ„å¯¹æ¯” (ç®€åŒ–ç‰ˆ)")
    print("="*70)

    model_old, model_new = test_initialization()

    print("\n[éªŒè¯] æ¨¡å‹ç»“æ„å¯¹æ¯”...")

    # éªŒè¯ä¸¤ä¸ªæ¨¡å‹éƒ½æœ‰ transformer
    assert hasattr(model_old, 'transformer')
    assert hasattr(model_new, 'transformer')
    print("âœ“ ä¸¤ä¸ªç³»ç»Ÿéƒ½æœ‰ transformer")

    # éªŒè¯ä¸¤ä¸ªæ¨¡å‹éƒ½æœ‰ç›¸åŒçš„æ ¸å¿ƒç»„ä»¶
    assert hasattr(model_old, 'tokenizer')
    assert hasattr(model_new, 'tokenizer')
    print("âœ“ ä¸¤ä¸ªç³»ç»Ÿéƒ½æœ‰ tokenizer")

    # éªŒè¯é…ç½®ä¸€è‡´æ€§
    assert model_old.config.num_layers == model_new.config.num_layers
    assert model_old.config.num_heads == model_new.config.num_heads
    assert model_old.config.embed_dim == model_new.config.embed_dim
    print("âœ“ æ ¸å¿ƒé…ç½®ä¸€è‡´ (num_layers, num_heads, embed_dim)")

    print("\nâœ… æµ‹è¯• 4 é€šè¿‡: æ¨¡å‹ç»“æ„ä¸€è‡´\n")


def test_cache_operations():
    """æµ‹è¯• cache æ“ä½œ (ä»…æ–°ç³»ç»Ÿ)"""
    print("\n" + "="*70)
    print("æµ‹è¯• 5: Cache æ“ä½œ (æ–°ç³»ç»Ÿ)")
    print("="*70)

    _, model_new = test_initialization()

    if not model_new.use_new_cache_manager:
        print("âš ï¸ æ–°ç³»ç»Ÿæœªå¯ç”¨,è·³è¿‡æ­¤æµ‹è¯•")
        return

    manager = model_new.kv_cache_manager

    # åˆ›å»ºæµ‹è¯•ç”¨çš„ KeysValues
    from lzero.model.unizero_world_models.kv_caching import KeysValues

    print("\nåˆ›å»ºæµ‹è¯•ç”¨ KeysValues...")
    test_kv = KeysValues(
        num_samples=2,
        num_heads=8,
        max_tokens=20,
        embed_dim=768,
        num_layers=2,
        device=torch.device('cpu')
    )
    print(f"âœ“ KeysValues åˆ›å»ºæˆåŠŸ: {len(test_kv)} layers")

    # æµ‹è¯• set/get
    cache_key = 98765
    env_id = 0

    print(f"\nSet cache: env_id={env_id}, key={cache_key}")
    index = manager.set_init_cache(env_id=env_id, cache_key=cache_key, kv_cache=test_kv)
    print(f"âœ“ Set æˆåŠŸ: index={index}")

    print(f"\nGet cache: env_id={env_id}, key={cache_key}")
    retrieved = manager.get_init_cache(env_id=env_id, cache_key=cache_key)
    assert retrieved is not None
    assert retrieved is test_kv
    print(f"âœ“ Get æˆåŠŸ")

    # æµ‹è¯•ç»Ÿè®¡
    stats = manager.get_stats_summary()
    print(f"\nç»Ÿè®¡ä¿¡æ¯:")
    print(f"  {stats['init_pools']['env_0']}")

    print("\nâœ… æµ‹è¯• 5 é€šè¿‡: Cache æ“ä½œæ­£å¸¸\n")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("KV Cache é‡æ„å‰åä¸€è‡´æ€§æµ‹è¯•")
    print("åŸºäº atari_unizero_segment_config ç®€åŒ–ç‰ˆ")
    print("="*70)

    try:
        # æµ‹è¯• 1: åˆå§‹åŒ–
        test_initialization()

        # æµ‹è¯• 2: Cache ç»“æ„
        test_cache_structures()

        # æµ‹è¯• 3: clear_caches
        test_clear_caches()

        # æµ‹è¯• 4: æ¨¡å‹å‰å‘ä¼ æ’­
        test_model_forward()

        # æµ‹è¯• 5: Cache æ“ä½œ
        test_cache_operations()

        # æ€»ç»“
        print("\n" + "="*70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("="*70)
        print("\nâœ… ä¸€è‡´æ€§éªŒè¯æˆåŠŸ:")
        print("  1. âœ“ ä¸¤ä¸ªç³»ç»Ÿéƒ½èƒ½æ­£ç¡®åˆå§‹åŒ–")
        print("  2. âœ“ Cache æ•°æ®ç»“æ„æ­£ç¡®")
        print("  3. âœ“ clear_caches() æ–¹æ³•å·¥ä½œæ­£å¸¸")
        print("  4. âœ“ æ¨¡å‹å‰å‘ä¼ æ’­æ­£å¸¸")
        print("  5. âœ“ Cache æ“ä½œåŠŸèƒ½æ­£å¸¸ (æ–°ç³»ç»Ÿ)")
        print("\nç»“è®º:")
        print("  â€¢ æ—§ç³»ç»Ÿ: ç»§ç»­æ­£å¸¸å·¥ä½œ,æœªå—å½±å“")
        print("  â€¢ æ–°ç³»ç»Ÿ: åŠŸèƒ½æ­£å¸¸,å¯ä»¥é€šè¿‡é…ç½®å¯ç”¨")
        print("  â€¢ å‘åå…¼å®¹: ä¿æŒå®Œæ•´")
        print("  â€¢ åˆ‡æ¢æ–¹å¼: é…ç½® use_new_cache_manager=True/False")
        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
        print("  â€¢ åœ¨å®é™…è®­ç»ƒä¸­æµ‹è¯•æ–°ç³»ç»Ÿ")
        print("  â€¢ å¯¹æ¯”è®­ç»ƒæ€§èƒ½å’Œå†…å­˜ä½¿ç”¨")
        print("  â€¢ æ”¶é›† cache å‘½ä¸­ç‡ç»Ÿè®¡")
        print("="*70 + "\n")

        return True

    except Exception as e:
        print("\n" + "="*70)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("="*70)
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
