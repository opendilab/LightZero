"""
KV Cache ç³»ç»Ÿåˆ‡æ¢æµ‹è¯•è„šæœ¬
=============================

æµ‹è¯•æ–°æ—§ KV Cache ç³»ç»Ÿçš„é…ç½®åˆ‡æ¢åŠŸèƒ½ã€‚

è¿è¡Œæ–¹å¼:
    python tests/test_kv_cache_system_switch.py
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import torch
from unittest.mock import Mock
from lzero.model.unizero_world_models.world_model import WorldModel
from lzero.model.unizero_world_models.transformer import TransformerConfig
from lzero.model.unizero_world_models.tokenizer import Tokenizer


def create_test_config(use_new_cache=False):
    """åˆ›å»ºæµ‹è¯•é…ç½®"""
    config = TransformerConfig(
        tokens_per_block=2,
        max_blocks=10,
        max_tokens=20,
        context_length=8,
        num_layers=2,
        num_heads=4,
        embed_dim=256,
        embed_pdrop=0.1,
        resid_pdrop=0.1,
        attn_pdrop=0.1,
        action_space_size=6,
        group_size=8,
        task_num=1,
        env_num=4,
        support_size=101,
        num_simulations=25,
        game_segment_length=100,
        obs_type='image',
        observation_shape=(3, 64, 64),
        image_channel=3,
        device='cpu',
        continuous_action_space=False,
        use_new_cache_manager=use_new_cache,  # âœ¨ å…³é”®é…ç½®
    )
    return config


def create_test_tokenizer(config):
    """åˆ›å»ºæµ‹è¯•ç”¨çš„ tokenizer"""
    tokenizer = Tokenizer(
        obs_type=config.obs_type,
        obs_shape=config.observation_shape,
        embedding_dim=config.embed_dim,
        use_norm=False,
        group_size=config.group_size,
        device=config.device,
    )
    return tokenizer


def test_old_cache_system():
    """æµ‹è¯•æ—§çš„ cache ç³»ç»Ÿ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 1: æ—§ KV Cache ç³»ç»Ÿ")
    print("="*70)

    config = create_test_config(use_new_cache=False)
    tokenizer = create_test_tokenizer(config)
    model = WorldModel(config, tokenizer)

    # éªŒè¯
    assert hasattr(model, 'use_new_cache_manager')
    assert model.use_new_cache_manager == False
    assert hasattr(model, 'past_kv_cache_init_infer_envs')
    assert hasattr(model, 'past_kv_cache_recurrent_infer')
    assert hasattr(model, 'keys_values_wm_list')
    assert not hasattr(model, 'kv_cache_manager')

    print("âœ“ æ—§ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
    print(f"  - use_new_cache_manager: {model.use_new_cache_manager}")
    print(f"  - past_kv_cache_init_infer_envs: {len(model.past_kv_cache_init_infer_envs)} envs")
    print(f"  - past_kv_cache_recurrent_infer: initialized")

    # æµ‹è¯• clear_caches
    model.clear_caches()
    print("âœ“ æ—§ç³»ç»Ÿ clear_caches() æ‰§è¡ŒæˆåŠŸ")

    print("\nâœ… æµ‹è¯• 1 é€šè¿‡: æ—§ç³»ç»Ÿå·¥ä½œæ­£å¸¸\n")


def test_new_cache_system():
    """æµ‹è¯•æ–°çš„ cache ç³»ç»Ÿ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 2: æ–° KV Cache ç³»ç»Ÿ")
    print("="*70)

    config = create_test_config(use_new_cache=True)
    tokenizer = create_test_tokenizer(config)
    model = WorldModel(config, tokenizer)

    # éªŒè¯
    assert hasattr(model, 'use_new_cache_manager')
    assert model.use_new_cache_manager == True
    assert hasattr(model, 'kv_cache_manager')
    assert hasattr(model.kv_cache_manager, 'init_pools')
    assert hasattr(model.kv_cache_manager, 'recur_pool')
    assert hasattr(model.kv_cache_manager, 'wm_pool')

    print("âœ“ æ–°ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
    print(f"  - use_new_cache_manager: {model.use_new_cache_manager}")
    print(f"  - kv_cache_manager: {model.kv_cache_manager}")
    print(f"  - init_pools: {len(model.kv_cache_manager.init_pools)} pools")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = model.kv_cache_manager.get_stats_summary()
    print(f"âœ“ ç»Ÿè®¡ä¿¡æ¯è·å–æˆåŠŸ:")
    print(f"  - stats_enabled: {stats['stats_enabled']}")
    print(f"  - init_pools: {len(stats['init_pools'])} envs")

    # æµ‹è¯• clear_caches
    model.clear_caches()
    print("âœ“ æ–°ç³»ç»Ÿ clear_caches() æ‰§è¡ŒæˆåŠŸ")

    print("\nâœ… æµ‹è¯• 2 é€šè¿‡: æ–°ç³»ç»Ÿå·¥ä½œæ­£å¸¸\n")


def test_cache_operations():
    """æµ‹è¯•åŸºæœ¬çš„ cache æ“ä½œ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 3: æ–°ç³»ç»Ÿ Cache æ“ä½œ")
    print("="*70)

    config = create_test_config(use_new_cache=True)
    tokenizer = create_test_tokenizer(config)
    model = WorldModel(config, tokenizer)

    manager = model.kv_cache_manager

    # åˆ›å»ºæµ‹è¯•ç”¨çš„ KeysValues å¯¹è±¡
    from lzero.model.unizero_world_models.kv_caching import KeysValues

    test_kv = KeysValues(
        num_samples=1,
        num_heads=4,
        max_tokens=20,
        embed_dim=256,
        num_layers=2,
        device=torch.device('cpu')
    )

    # æµ‹è¯• set å’Œ get
    cache_key = 12345
    index = manager.set_init_cache(env_id=0, cache_key=cache_key, kv_cache=test_kv)
    print(f"âœ“ Set cache: env_id=0, cache_key={cache_key}, index={index}")

    retrieved = manager.get_init_cache(env_id=0, cache_key=cache_key)
    assert retrieved is not None
    assert retrieved is test_kv
    print(f"âœ“ Get cache: retrieved successfully")

    # æµ‹è¯• cache miss
    missing = manager.get_init_cache(env_id=0, cache_key=99999)
    assert missing is None
    print(f"âœ“ Cache miss: returned None as expected")

    # æµ‹è¯•ç»Ÿè®¡
    stats = manager.get_stats_summary()
    print(f"âœ“ Stats after operations:")
    print(f"  - {stats['init_pools']['env_0']}")

    print("\nâœ… æµ‹è¯• 3 é€šè¿‡: Cache æ“ä½œæ­£å¸¸\n")


def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    print("\n" + "="*70)
    print("æµ‹è¯• 4: å‘åå…¼å®¹æ€§")
    print("="*70)

    config = create_test_config(use_new_cache=True)
    tokenizer = create_test_tokenizer(config)
    model = WorldModel(config, tokenizer)

    # éªŒè¯å‘åå…¼å®¹çš„å¼•ç”¨
    assert hasattr(model, 'keys_values_wm_list')
    assert hasattr(model, 'keys_values_wm_size_list')
    assert model.keys_values_wm_list is model.kv_cache_manager.keys_values_wm_list
    assert model.keys_values_wm_size_list is model.kv_cache_manager.keys_values_wm_size_list

    print("âœ“ å‘åå…¼å®¹å¼•ç”¨éªŒè¯é€šè¿‡")
    print(f"  - keys_values_wm_list: {type(model.keys_values_wm_list)}")
    print(f"  - keys_values_wm_size_list: {type(model.keys_values_wm_size_list)}")

    print("\nâœ… æµ‹è¯• 4 é€šè¿‡: å‘åå…¼å®¹æ€§æ­£å¸¸\n")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("KV Cache ç³»ç»Ÿåˆ‡æ¢æµ‹è¯•")
    print("="*70)

    try:
        test_old_cache_system()
        test_new_cache_system()
        test_cache_operations()
        test_backward_compatibility()

        print("\n" + "="*70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("="*70)
        print("\nâœ… Phase 1 é›†æˆæˆåŠŸ:")
        print("  - æ—§ç³»ç»Ÿä»æ­£å¸¸å·¥ä½œ")
        print("  - æ–°ç³»ç»Ÿå¯ä»¥é€šè¿‡é…ç½®å¯ç”¨")
        print("  - æ–°æ—§ç³»ç»Ÿå¯ä»¥æ— ç¼åˆ‡æ¢")
        print("  - Cache æ“ä½œåŠŸèƒ½æ­£å¸¸")
        print("  - å‘åå…¼å®¹æ€§ä¿æŒ")
        print("\nä¸‹ä¸€æ­¥: å¯ä»¥å¼€å§‹åœ¨å®é™…è®­ç»ƒä¸­æµ‹è¯•æ–°ç³»ç»Ÿ")
        print("="*70 + "\n")

        return True

    except Exception as e:
        print("\n" + "="*70)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("="*70)
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
