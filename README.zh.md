<div id="top"></div>

# LightZero

<div align="center">
    <img width="1000px" height="auto" src="https://github.com/opendilab/LightZero/blob/main/LightZero.png"></a>
</div>

---

[![Twitter](https://img.shields.io/twitter/url?style=social&url=https%3A%2F%2Ftwitter.com%2Fopendilab)](https://twitter.com/opendilab)
[![PyPI](https://img.shields.io/pypi/v/LightZero)](https://pypi.org/project/LightZero/)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/LightZero)
![Loc](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/HansBug/e002642132ec758e99264118c66778a4/raw/loc.json)
![Comments](https://img.shields.io/endpoint?url=https://gist.githubusercontent.com/HansBug/e002642132ec758e99264118c66778a4/raw/comments.json)

[![Code Test](https://github.com/opendilab/LightZero/workflows/Code%20Test/badge.svg)](https://github.com/opendilab/LightZero/actions?query=workflow%3A%22Code+Test%22)
[![Badge Creation](https://github.com/opendilab/LightZero/workflows/Badge%20Creation/badge.svg)](https://github.com/opendilab/LightZero/actions?query=workflow%3A%22Badge+Creation%22)
[![Package Release](https://github.com/opendilab/LightZero/workflows/Package%20Release/badge.svg)](https://github.com/opendilab/LightZero/actions?query=workflow%3A%22Package+Release%22)

![GitHub Org's stars](https://img.shields.io/github/stars/opendilab)
[![GitHub stars](https://img.shields.io/github/stars/opendilab/LightZero)](https://github.com/opendilab/LightZero/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/opendilab/LightZero)](https://github.com/opendilab/LightZero/network)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/opendilab/LightZero)
[![GitHub issues](https://img.shields.io/github/issues/opendilab/LightZero)](https://github.com/opendilab/LightZero/issues)
[![GitHub pulls](https://img.shields.io/github/issues-pr/opendilab/LightZero)](https://github.com/opendilab/LightZero/pulls)
[![Contributors](https://img.shields.io/github/contributors/opendilab/LightZero)](https://github.com/opendilab/LightZero/graphs/contributors)
[![GitHub license](https://img.shields.io/github/license/opendilab/LightZero)](https://github.com/opendilab/LightZero/blob/master/LICENSE)

æœ€è¿‘æ›´æ–°äº 2024.02.08 LightZero-v0.0.4

> LightZero æ˜¯ä¸€ä¸ªè½»é‡ã€é«˜æ•ˆã€æ˜“æ‡‚çš„ MCTS+RL å¼€æºç®—æ³•åº“ã€‚

[English](https://github.com/opendilab/LightZero/blob/main/README.md) | ç®€ä½“ä¸­æ–‡ | [è®ºæ–‡é“¾æ¥](https://arxiv.org/pdf/2310.08348.pdf)

## èƒŒæ™¯

ä»¥ AlphaZero, MuZero ä¸ºä»£è¡¨çš„ç»“åˆè’™ç‰¹å¡æ´›æ ‘æœç´¢ (Monte Carlo Tree Search, MCTS) å’Œæ·±åº¦å¼ºåŒ–å­¦ä¹  (Deep Reinforcemeent Learning, DRL) çš„æ–¹æ³•ï¼Œåœ¨è¯¸å¦‚å›´æ£‹ï¼ŒAtari ç­‰å„ç§æ¸¸æˆä¸Šå–å¾—äº†è¶…äººçš„æ°´å¹³ï¼Œä¹Ÿåœ¨è¯¸å¦‚è›‹ç™½è´¨ç»“æ„é¢„æµ‹ï¼ŒçŸ©é˜µä¹˜æ³•ç®—æ³•å¯»æ‰¾ç­‰ç§‘å­¦é¢†åŸŸå–å¾—äº†å¯å–œçš„è¿›å±•ã€‚ä¸‹å›¾ä¸ºè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ç®—æ³•æ—çš„å‘å±•å†å²ï¼š
![pipeline](assets/mcts_rl_evolution_overview.png)

## æ¦‚è§ˆ

**LightZero** æ˜¯ä¸€ä¸ªç»“åˆäº†è’™ç‰¹å¡æ´›æ ‘æœç´¢å’Œå¼ºåŒ–å­¦ä¹ çš„å¼€æºç®—æ³•å·¥å…·åŒ…ã€‚ å®ƒæ”¯æŒä¸€ç³»åˆ—åŸºäº MCTS çš„ RL ç®—æ³•ï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼š
- è½»é‡ã€‚
- é«˜æ•ˆã€‚
- æ˜“æ‡‚ã€‚

è¯¦æƒ…è¯·å‚è€ƒ[ç‰¹ç‚¹](#features)ã€[æ¡†æ¶ç»“æ„](#framework-structure)å’Œ[é›†æˆç®—æ³•](#integrated-algorithms)ã€‚

**LightZero** çš„ç›®æ ‡æ˜¯**æ ‡å‡†åŒ– MCTS ç®—æ³•æ—ï¼Œä»¥åŠ é€Ÿç›¸å…³ç ”ç©¶å’Œåº”ç”¨ã€‚** [Benchmark](#benchmark) ä¸­ä»‹ç»äº†ç›®å‰æ‰€æœ‰å·²å®ç°ç®—æ³•çš„æ€§èƒ½æ¯”è¾ƒã€‚

### å¯¼èˆª
- [æ¦‚è§ˆ](#æ¦‚è§ˆ)
    - [å¯¼èˆª](#å¯¼èˆª)
    - [ç‰¹ç‚¹](#ç‰¹ç‚¹)
    - [æ¡†æ¶ç»“æ„](#æ¡†æ¶ç»“æ„)
    - [é›†æˆç®—æ³•](#é›†æˆç®—æ³•)
- [å®‰è£…æ–¹æ³•](#å®‰è£…æ–¹æ³•)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [åŸºçº¿ç®—æ³•æ¯”è¾ƒ](#åŸºçº¿ç®—æ³•æ¯”è¾ƒ)
- [MCTSç›¸å…³ç¬”è®°](#MCTS-ç›¸å…³ç¬”è®°)
    - [è®ºæ–‡ç¬”è®°](#è®ºæ–‡ç¬”è®°)
    - [ç®—æ³•æ¡†æ¶å›¾](#ç®—æ³•æ¡†æ¶å›¾)
- [MCTSç›¸å…³è®ºæ–‡](#MCTS-ç›¸å…³è®ºæ–‡)
    - [é‡è¦è®ºæ–‡](#é‡è¦è®ºæ–‡)
    - [å…¶ä»–è®ºæ–‡](#å…¶ä»–è®ºæ–‡)
- [åé¦ˆæ„è§å’Œè´¡çŒ®](#åé¦ˆæ„è§å’Œè´¡çŒ®)
- [å¼•ç”¨](#å¼•ç”¨)
- [è‡´è°¢](#è‡´è°¢)
- [è®¸å¯è¯](#è®¸å¯è¯)

### ç‰¹ç‚¹
**è½»é‡**ï¼šLightZero ä¸­é›†æˆäº†å¤šç§ MCTS æ—ç®—æ³•ï¼Œèƒ½å¤Ÿåœ¨åŒä¸€æ¡†æ¶ä¸‹è½»é‡åŒ–åœ°è§£å†³å¤šç§å±æ€§çš„å†³ç­–é—®é¢˜ã€‚

**é«˜æ•ˆ**ï¼šLightZero é’ˆå¯¹ MCTS æ—ç®—æ³•ä¸­è€—æ—¶æœ€é•¿çš„ç¯èŠ‚ï¼Œé‡‡ç”¨æ··åˆå¼‚æ„è®¡ç®—ç¼–ç¨‹æé«˜è®¡ç®—æ•ˆç‡ã€‚

**æ˜“æ‡‚**ï¼šLightZero ä¸ºæ‰€æœ‰é›†æˆçš„ç®—æ³•æä¾›äº†è¯¦ç»†æ–‡æ¡£å’Œç®—æ³•æ¡†æ¶å›¾ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£ç®—æ³•å†…æ ¸ï¼Œåœ¨åŒä¸€èŒƒå¼ä¸‹æ¯”è¾ƒç®—æ³•ä¹‹é—´çš„å¼‚åŒã€‚åŒæ—¶ï¼ŒLightZero ä¹Ÿä¸ºç®—æ³•çš„ä»£ç å®ç°æä¾›äº†å‡½æ•°è°ƒç”¨å›¾å’Œç½‘ç»œç»“æ„å›¾ï¼Œä¾¿äºç”¨æˆ·å®šä½å…³é”®ä»£ç ã€‚

### æ¡†æ¶ç»“æ„

<p align="center">
  <img src="assets/lightzero_pipeline.svg" alt="Image Description 2" width="50%" height="auto" style="margin: 0 1%;">
</p>

ä¸Šå›¾æ˜¯ LightZero çš„æ¡†æ¶æµç¨‹å›¾ã€‚æˆ‘ä»¬åœ¨ä¸‹é¢ç®€ä»‹å…¶ä¸­çš„3ä¸ªæ ¸å¿ƒæ¨¡å—:

**Model**:
``Model`` ç”¨äºå®šä¹‰ç½‘ç»œç»“æ„ï¼ŒåŒ…å«``__init__``å‡½æ•°ç”¨äºåˆå§‹åŒ–ç½‘ç»œç»“æ„ï¼Œå’Œ``forward``å‡½æ•°ç”¨äºè®¡ç®—ç½‘ç»œçš„å‰å‘ä¼ æ’­ã€‚

**Policy**:
``Policy`` å®šä¹‰äº†å¯¹ç½‘ç»œçš„æ›´æ–°æ–¹å¼å’Œä¸ç¯å¢ƒäº¤äº’çš„æ–¹å¼ï¼ŒåŒ…æ‹¬ä¸‰ä¸ªè¿‡ç¨‹ï¼Œåˆ†åˆ«æ˜¯è®­ç»ƒè¿‡ç¨‹ï¼ˆlearnï¼‰ã€é‡‡æ ·è¿‡ç¨‹ï¼ˆcollectï¼‰å’Œè¯„ä¼°è¿‡ç¨‹ï¼ˆevaluateï¼‰ã€‚

**MCTS**:

``MCTS`` å®šä¹‰äº†è’™ç‰¹å¡æ´›æœç´¢æ ‘çš„ç»“æ„å’Œä¸``Policy``çš„äº¤äº’æ–¹å¼ã€‚``MCTS``çš„å®ç°åŒ…æ‹¬ python å’Œ cpp ä¸¤ç§ï¼Œåˆ†åˆ«åœ¨``ptree``å’Œ``ctree``ä¸­å®ç°ã€‚

å…³äº LightZero çš„æ–‡ä»¶ç»“æ„ï¼Œè¯·å‚è€ƒ [lightzero_file_structure](https://github.com/opendilab/LightZero/blob/main/assets/lightzero_file_structure.svg)ã€‚

### é›†æˆç®—æ³•
LightZero æ˜¯åŸºäº [PyTorch](https://pytorch.org/) å®ç°çš„ MCTS ç®—æ³•åº“ï¼Œåœ¨ MCTS çš„å®ç°ä¸­ä¹Ÿç”¨åˆ°äº† cython å’Œ cppã€‚åŒæ—¶ï¼ŒLightZero çš„æ¡†æ¶ä¸»è¦åŸºäº [DI-engine](https://github.com/opendilab/DI-engine) å®ç°ã€‚ç›®å‰ LightZero ä¸­é›†æˆçš„ç®—æ³•åŒ…æ‹¬ï¼š
- [AlphaZero](https://www.science.org/doi/10.1126/science.aar6404)
- [MuZero](https://arxiv.org/abs/1911.08265)
- [Sampled MuZero](https://arxiv.org/abs/2104.06303)
- [Stochastic MuZero](https://openreview.net/pdf?id=X6D9bAHhBQ1)
- [EfficientZero](https://arxiv.org/abs/2111.00210)
- [Gumbel MuZero](https://openreview.net/pdf?id=bERaNdoegnO&)


LightZero ç›®å‰æ”¯æŒçš„ç¯å¢ƒåŠç®—æ³•å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š

| Env./Algo.    | AlphaZero | MuZero | EfficientZero | Sampled EfficientZero | Gumbel MuZero | Stochastic MuZero | 
|---------------| --------- | ------ |-------------| ------------------ | ---------- |----------------|
| TicTacToe     | âœ”       | âœ”      | ğŸ”’           | ğŸ”’                | âœ”          | ğŸ”’             |
| Gomoku        | âœ”       | âœ”      | ğŸ”’          | ğŸ”’               | âœ”          | ğŸ”’             |
| Connect4      | âœ”       | âœ”      | ğŸ”’          | ğŸ”’               | ğŸ”’           | ğŸ”’             |
| 2048          | âœ”       | âœ”      | ğŸ”’            | ğŸ”’                | ğŸ”’           | âœ”              |
| Chess         | ğŸ”’       | ğŸ”’     | ğŸ”’          | ğŸ”’               | ğŸ”’         | ğŸ”’             |
| Go            | ğŸ”’       | ğŸ”’     | ğŸ”’          | ğŸ”’               | ğŸ”’         | ğŸ”’             |
| CartPole      | ---       | âœ”      | âœ”           | âœ”                | âœ”          | âœ”              |
| Pendulum      | ---       | âœ”      | âœ”           | âœ”                | âœ”          | âœ”              |
| LunarLander   | ---       | âœ”      | âœ”           | âœ”                | âœ”          | âœ”              |
| BipedalWalker | ---       | âœ”      | âœ”           | âœ”                | âœ”          | ğŸ”’              |
| Atari         | ---       | âœ”      | âœ”           | âœ”                | âœ”          | âœ”              |
| MuJoCo        | ---       | âœ”     | âœ”          | âœ”                | ğŸ”’         | ğŸ”’               |
| MiniGrid      | ---       | âœ”     | âœ”          | âœ”               | ğŸ”’         | ğŸ”’             |
| Bsuite        | ---       | âœ”     | âœ”          | âœ”               | ğŸ”’         | ğŸ”’             |

<sup>(1): "âœ”" è¡¨ç¤ºå¯¹åº”çš„é¡¹ç›®å·²ç»å®Œæˆå¹¶ç»è¿‡è‰¯å¥½çš„æµ‹è¯•ã€‚</sup>

<sup>(2): "ğŸ”’" è¡¨ç¤ºå¯¹åº”çš„é¡¹ç›®åœ¨ç­‰å¾…åˆ—è¡¨ä¸­ï¼ˆæ­£åœ¨è¿›è¡Œä¸­ï¼‰ã€‚</sup>

<sup>(3): "---" è¡¨ç¤ºè¯¥ç®—æ³•ä¸æ”¯æŒæ­¤ç¯å¢ƒã€‚</sup>

## å®‰è£…æ–¹æ³•

å¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤ä» Github çš„æºç ä¸­å®‰è£…æœ€æ–°ç‰ˆçš„ LightZeroï¼š

```bash
git clone https://github.com/opendilab/LightZero.git
cd LightZero
pip3 install -e .
```

è¯·æ³¨æ„ï¼ŒLightZero ç›®å‰ä»…æ”¯æŒåœ¨ `Linux` å’Œ `macOS` å¹³å°ä¸Šè¿›è¡Œç¼–è¯‘ã€‚
æˆ‘ä»¬æ­£åœ¨ç§¯æå°†è¯¥æ”¯æŒæ‰©å±•åˆ° `Windows` å¹³å°ã€‚ 

### ä½¿ç”¨ Docker è¿›è¡Œå®‰è£…

æˆ‘ä»¬ä¹Ÿæä¾›äº†ä¸€ä¸ªDockerfileï¼Œç”¨äºè®¾ç½®åŒ…å«è¿è¡Œ LightZero åº“æ‰€éœ€æ‰€æœ‰ä¾èµ–é¡¹çš„ç¯å¢ƒã€‚æ­¤ Docker é•œåƒåŸºäº Ubuntu 20.04ï¼Œå¹¶å®‰è£…äº†Python 3.8ä»¥åŠå…¶ä»–å¿…è¦çš„å·¥å…·å’Œåº“ã€‚
ä»¥ä¸‹æ˜¯å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬çš„ Dockerfile æ¥æ„å»º Docker é•œåƒï¼Œä»è¯¥é•œåƒè¿è¡Œä¸€ä¸ªå®¹å™¨ï¼Œå¹¶åœ¨å®¹å™¨å†…æ‰§è¡Œ LightZero ä»£ç çš„æ­¥éª¤ã€‚

1. **ä¸‹è½½ Dockerfile**ï¼šDockerfile ä½äº LightZero ä»“åº“çš„æ ¹ç›®å½•ä¸­ã€‚å°†æ­¤[æ–‡ä»¶](https://github.com/opendilab/LightZero/blob/main/Dockerfile)ä¸‹è½½åˆ°æ‚¨çš„æœ¬åœ°æœºå™¨ã€‚

2. **å‡†å¤‡æ„å»ºä¸Šä¸‹æ–‡**ï¼šåœ¨æ‚¨çš„æœ¬åœ°æœºå™¨ä¸Šåˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºç›®å½•ï¼Œå°† Dockerfile ç§»åŠ¨åˆ°æ­¤ç›®å½•ï¼Œå¹¶å¯¼èˆªåˆ°æ­¤ç›®å½•ã€‚è¿™ä¸€æ­¥æœ‰åŠ©äºåœ¨æ„å»ºè¿‡ç¨‹ä¸­é¿å…å‘ Docker å®ˆæŠ¤è¿›ç¨‹å‘é€ä¸å¿…è¦çš„æ–‡ä»¶ã€‚
    ```bash
    mkdir lightzero-docker
    mv Dockerfile lightzero-docker/
    cd lightzero-docker/
    ```
3. **æ„å»º Docker é•œåƒ**ï¼šä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ„å»º Docker é•œåƒã€‚æ­¤å‘½ä»¤åº”åœ¨åŒ…å« Dockerfile çš„ç›®å½•å†…è¿è¡Œã€‚
    ```bash
    docker build -t ubuntu-py38-lz:latest -f ./Dockerfile .
    ```
4. **ä»é•œåƒè¿è¡Œå®¹å™¨**ï¼šä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä»¥äº¤äº’æ¨¡å¼å¯åŠ¨ä¸€ä¸ª Bash shell çš„å®¹å™¨ã€‚
    ```bash
    docker run -dit --rm ubuntu-py38-lz:latest /bin/bash
    ```
5. **åœ¨å®¹å™¨å†…æ‰§è¡Œ LightZero ä»£ç **ï¼šä¸€æ—¦ä½ åœ¨å®¹å™¨å†…éƒ¨ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œç¤ºä¾‹ Python è„šæœ¬ï¼š
    ```bash
    python ./LightZero/zoo/classic_control/cartpole/config/cartpole_muzero_config.py
    ```

## å¿«é€Ÿå¼€å§‹
ä½¿ç”¨å¦‚ä¸‹ä»£ç åœ¨ [CartPole](https://gymnasium.farama.org/environments/classic_control/cart_pole/) ç¯å¢ƒä¸Šå¿«é€Ÿè®­ç»ƒä¸€ä¸ª MuZero æ™ºèƒ½ä½“:

```bash
cd LightZero
python3 -u zoo/classic_control/cartpole/config/cartpole_muzero_config.py
```

ä½¿ç”¨å¦‚ä¸‹ä»£ç åœ¨ [Pong](https://gymnasium.farama.org/environments/atari/pong/) ç¯å¢ƒä¸Šå¿«é€Ÿè®­ç»ƒä¸€ä¸ª MuZero æ™ºèƒ½ä½“ï¼š

```bash
cd LightZero
python3 -u zoo/atari/config/atari_muzero_config.py
```

ä½¿ç”¨å¦‚ä¸‹ä»£ç åœ¨ [TicTacToe](https://en.wikipedia.org/wiki/Tic-tac-toe) ç¯å¢ƒä¸Šå¿«é€Ÿè®­ç»ƒä¸€ä¸ª MuZero æ™ºèƒ½ä½“ï¼š

```bash
cd LightZero
python3 -u zoo/board_games/tictactoe/config/tictactoe_muzero_bot_mode_config.py
```

## åŸºçº¿ç®—æ³•æ¯”è¾ƒ

<details open><summary>ç‚¹å‡»æŠ˜å </summary>

- [AlphaZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/alphazero.py) å’Œ [MuZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/muzero.py) åœ¨3ä¸ªæ£‹ç±»æ¸¸æˆï¼ˆ[TicTacToe (äº•å­—æ£‹)](https://github.com/opendilab/LightZero/blob/main/zoo/board_games/tictactoe/envs/tictactoe_env.py)ï¼Œ[Connect4](https://github.com/opendilab/LightZero/blob/main/zoo/board_games/connect4/envs/connect4_env.py) å’Œ [Gomoku (äº”å­æ£‹)](https://github.com/opendilab/LightZero/blob/main/zoo/board_games/gomoku/envs/gomoku_env.py)ï¼‰ä¸Šçš„åŸºçº¿ç»“æœï¼š
<p align="center">
  <img src="assets/benchmark/main/tictactoe_bot-mode_main.png" alt="tictactoe_bot-mode_main" width="30%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/connect4_bot-mode_main.png" alt="connect4_bot-mode_main" width="30%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/gomoku_bot-mode_main.png" alt="gomoku_bot-mode_main" width="30%" height="auto" style="margin: 0 1%;">
</p>

- [MuZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/muzero.py)ï¼Œ[MuZero w/ SSL](https://github.com/opendilab/LightZero/blob/main/lzero/policy/muzero.py)ï¼Œ[EfficientZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/efficientzero.py) å’Œ [Sampled EfficientZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/sampled_efficientzero.py) åœ¨3ä¸ªä»£è¡¨æ€§çš„ [Atari](https://github.com/opendilab/LightZero/blob/main/zoo/atari/envs/atari_lightzero_env.py) ç¦»æ•£åŠ¨ä½œç©ºé—´ç¯å¢ƒä¸Šçš„åŸºçº¿ç»“æœï¼š
<p align="center">
  <img src="assets/benchmark/main/pong_main.png" alt="pong_main" width="23%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/qbert_main.png" alt="qbert_main" width="23%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/mspacman_main.png" alt="mspacman_main" width="23%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/ablation/mspacman_sez_K.png" alt="mspacman_sez_K" width="23%" height="auto" style="margin: 0 1%;">
</p>

- [Sampled EfficientZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/sampled_efficientzero.py)ï¼ˆåŒ…æ‹¬ ``Factored/Gaussian`` 2ç§ç­–ç•¥è¡¨å¾æ–¹æ³•ï¼‰åœ¨5ä¸ªè¿ç»­åŠ¨ä½œç©ºé—´ç¯å¢ƒï¼ˆ[Pendulum-v1](https://github.com/opendilab/LightZero/blob/main/zoo/classic_control/pendulum/envs/pendulum_lightzero_env.py)ï¼Œ[LunarLanderContinuous-v2](https://github.com/opendilab/LightZero/blob/main/zoo/box2d/lunarlander/envs/lunarlander_env.py)ï¼Œ[BipedalWalker-v3](https://github.com/opendilab/LightZero/blob/main/zoo/box2d/bipedalwalker/envs/bipedalwalker_env.py)ï¼Œ[Hopper-v3](https://github.com/opendilab/LightZero/blob/main/zoo/mujoco/envs/mujoco_lightzero_env.py) å’Œ [Walker2d-v3](https://github.com/opendilab/LightZero/blob/main/zoo/mujoco/envs/mujoco_lightzero_env.py)ï¼‰ä¸Šçš„åŸºçº¿ç»“æœï¼š
> å…¶ä¸­ ``Factored Policy`` è¡¨ç¤ºæ™ºèƒ½ä½“å­¦ä¹ ä¸€ä¸ªè¾“å‡ºç¦»æ•£åˆ†å¸ƒçš„ç­–ç•¥ç½‘ç»œï¼Œä¸Šè¿°5ç§ç¯å¢ƒæ‰‹åŠ¨ç¦»æ•£åŒ–åçš„åŠ¨ä½œç©ºé—´ç»´åº¦åˆ†åˆ«ä¸º11ã€49ï¼ˆ7^2ï¼‰ã€256ï¼ˆ4^4)ã€64 (4^3) å’Œ 4096 (4^6)ã€‚``Gaussian Policy``è¡¨ç¤ºæ™ºèƒ½ä½“å­¦ä¹ ä¸€ä¸ªç­–ç•¥ç½‘ç»œï¼Œè¯¥ç½‘ç»œç›´æ¥è¾“å‡ºé«˜æ–¯åˆ†å¸ƒçš„å‚æ•° Î¼ å’Œ Ïƒã€‚

<p align="center">
  <img src="assets/benchmark/main/pendulum_main.png" alt="pendulum_main" width="30%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/ablation/pendulum_sez_K.png" alt="pendulum_sez_K" width="30%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/lunarlander_main.png" alt="lunarlander_main" width="30%" height="auto" style="margin: 0 1%;">
</p>
<p align="center">
  <img src="assets/benchmark/main/bipedalwalker_main.png" alt="bipedalwalker_main" width="30%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/hopper_main.png" alt="hopper_main" width="31.5%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/walker2d_main.png" alt="walker2d_main" width="31.5%" height="auto" style="margin: 0 1%;">
</p>

- [Gumbel MuZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/gumbel_muzero.py) å’Œ [MuZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/muzero.py) åœ¨ä¸åŒæ¨¡æ‹Ÿæ¬¡æ•°ä¸‹ï¼Œåœ¨å››ä¸ªç¯å¢ƒï¼ˆ[PongNoFrameskip-v4](https://github.com/opendilab/LightZero/blob/main/zoo/atari/envs/atari_lightzero_env.py), [MsPacmanNoFrameskip-v4]((https://github.com/opendilab/LightZero/blob/main/zoo/atari/envs/atari_lightzero_env.py)), [Gomoku](https://github.com/opendilab/LightZero/blob/main/zoo/board_games/gomoku/envs/gomoku_env.py) å’Œ [LunarLanderContinuous-v2](https://github.com/opendilab/LightZero/blob/main/zoo/box2d/lunarlander/envs/lunarlander_env.py)ï¼‰ä¸Šçš„åŸºçº¿ç»“æœï¼š
<p align="center">
  <img src="assets/benchmark/ablation/pong_gmz_ns.png" alt="pong_gmz_ns" width="23%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/ablation/mspacman_gmz_ns.png" alt="mspacman_gmz_ns" width="23%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/ablation/gomoku_bot-mode_gmz_ns.png" alt="gomoku_bot-mode_gmz_ns" width="23%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/ablation/lunarlander_gmz_ns.png" alt="lunarlander_gmz_ns" width="23%" height="auto" style="margin: 0 1%;">
</p>

- [Stochastic MuZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/stochastic_muzero.py) å’Œ [MuZero](https://github.com/opendilab/LightZero/blob/main/lzero/policy/muzero.py) åœ¨å…·æœ‰ä¸åŒéšæœºæ€§ç¨‹åº¦çš„[2048ç¯å¢ƒ](https://github.com/opendilab/LightZero/blob/main/zoo/game_2048/envs/game_2048_env.py) (num_chances=2/5) ä¸Šçš„åŸºçº¿ç»“æœï¼š
<p align="center">
  <img src="assets/benchmark/main/2048/2048_stochasticmz_mz.png" alt="2048_stochasticmz_mz" width="30%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/2048/2048_stochasticmz_mz_nc5.png" alt="mspacman_gmz_ns" width="30%" height="auto" style="margin: 0 1%;">
</p>

- ç»“åˆä¸åŒçš„æ¢ç´¢æœºåˆ¶çš„ [MuZero w/ SSL](https://github.com/opendilab/LightZero/blob/main/lzero/policy/muzero.py) åœ¨ [MiniGrid ç¯å¢ƒ](https://github.com/opendilab/LightZero/blob/main/zoo/minigrid/envs/minigrid_lightzero_env.py)ä¸Šçš„åŸºçº¿ç»“æœï¼š
<p align="center">
  <img src="assets/benchmark/main/minigrid/keycorridors3r3_exploration.png" alt="keycorridors3r3_exploration" width="30%" height="auto" style="margin: 0 1%;">
  <img src="assets/benchmark/main/minigrid/fourrooms_exploration.png" alt="fourrooms_exploration" width="30%" height="auto" style="margin: 0 1%;">
</p>

</details>

## MCTS ç›¸å…³ç¬”è®°

### è®ºæ–‡ç¬”è®°

ä»¥ä¸‹æ˜¯ LightZero ä¸­é›†æˆç®—æ³•çš„ä¸­æ–‡è¯¦ç»†æ–‡æ¡£ï¼š

<details open><summary>ç‚¹å‡»æŠ˜å </summary>

[AlphaZero](https://github.com/opendilab/LightZero/blob/main/assets/paper_notes/AlphaZero.pdf)

[MuZero](https://github.com/opendilab/LightZero/blob/main/assets/paper_notes/MuZero.pdf)

[EfficientZero](https://github.com/opendilab/LightZero/blob/main/assets/paper_notes/EfficientZero.pdf)

[SampledMuZero](https://github.com/opendilab/LightZero/blob/main/assets/paper_notes/SampledMuZero.pdf)

[GumbelMuZero](https://github.com/opendilab/LightZero/blob/main/assets/paper_notes/GumbelMuZero.pdf)

[StochasticMuZero](https://github.com/opendilab/LightZero/blob/main/assets/paper_notes/StochasticMuZero.pdf)

[ç®—æ³•æ¦‚è§ˆå›¾ç¬¦å·è¡¨](https://github.com/opendilab/LightZero/blob/main/assets/paper_notes/NotationTable.pdf)

</details>

### ç®—æ³•æ¡†æ¶å›¾

ä»¥ä¸‹æ˜¯ LightZero ä¸­é›†æˆç®—æ³•çš„æ¡†æ¶æ¦‚è§ˆå›¾ï¼š

<details closed>
<summary>(ç‚¹å‡»æŸ¥çœ‹æ›´å¤š)</summary>

[MCTS](https://github.com/opendilab/LightZero/blob/main/assets/algo_overview/mcts_overview.pdf)

[AlphaZero](https://github.com/opendilab/LightZero/blob/main/assets/algo_overview/alphazero_overview.pdf)

[MuZero](https://github.com/opendilab/LightZero/blob/main/assets/algo_overview/muzero_overview.pdf)

[EfficientZero](https://github.com/opendilab/LightZero/blob/main/assets/algo_overview/efficientzero_overview.pdf)

[SampledMuZero](https://github.com/opendilab/LightZero/blob/main/assets/algo_overview/sampled_muzero_overview.pdf)

[GumbelMuZero](https://github.com/opendilab/LightZero/blob/main/assets/algo_overview/gumbel_muzero_overview.pdf)

</details>

## MCTS ç›¸å…³è®ºæ–‡

ä»¥ä¸‹æ˜¯å…³äº **MCTS** ç›¸å…³çš„è®ºæ–‡é›†åˆï¼Œ[è¿™ä¸€éƒ¨åˆ†](#MCTS-ç›¸å…³è®ºæ–‡) å°†ä¼šæŒç»­æ›´æ–°ï¼Œè¿½è¸ª MCTS çš„å‰æ²¿åŠ¨æ€ã€‚

### é‡è¦è®ºæ–‡

<details closed>
<summary>(ç‚¹å‡»æŸ¥çœ‹æ›´å¤š)</summary>

#### LightZero Implemented series

- [2018 _Science_ AlphaZero: A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play](https://www.science.org/doi/10.1126/science.aar6404)
- [2019 MuZero: Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model](https://arxiv.org/abs/1911.08265)
- [2021 EfficientZero: Mastering Atari Games with Limited Data](https://arxiv.org/abs/2111.00210)
- [2021 Sampled MuZero: Learning and Planning in Complex Action Spaces](https://arxiv.org/abs/2104.06303)
- [2022 Stochastic MuZero: Plannig in Stochastic Environments with A Learned Model](https://openreview.net/pdf?id=X6D9bAHhBQ1)
- [2022 Gumbel MuZero: Policy Improvement by Planning with Gumbel](https://openreview.net/pdf?id=bERaNdoegnO&)


#### AlphaGo series

- [2015 _Nature_ AlphaGo Mastering the game of Go with deep neural networks and tree search](https://www.nature.com/articles/nature16961)
- [2017 _Nature_ AlphaGo Zero Mastering the game of Go without human knowledge](https://www.nature.com/articles/nature24270)
- [2019 ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero](https://arxiv.org/abs/1902.04522) 
  - [Code](https://github.com/pytorch/ELF)
- [2023 Student of Games: A unified learning algorithm for both perfect and imperfect information games](https://www.science.org/doi/10.1126/sciadv.adg3256)

#### MuZero series
- [2022 Online and Offline Reinforcement Learning by Planning with a Learned Model](https://arxiv.org/abs/2104.06294)
- [2021 Vector Quantized Models for Planning](https://arxiv.org/abs/2106.04615)
- [2021 Muesli: Combining Improvements in Policy Optimization. ](https://arxiv.org/abs/2104.06159)

#### MCTS Analysis
- [2020 Monte-Carlo Tree Search as Regularized Policy Optimization](https://arxiv.org/abs/2007.12509)
- [2021 Self-Consistent Models and Values](https://arxiv.org/abs/2110.12840)
- [2022 Adversarial Policies Beat Professional-Level Go AIs](https://arxiv.org/abs/2211.00241)
- [2022 _PNAS_ Acquisition of Chess Knowledge in AlphaZero.](https://arxiv.org/abs/2111.09259)

#### MCTS Application
- [2023 Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search](https://openreview.net/pdf?id=ZTK3SefE8_Z)
- [2022 _Nature_ Discovering faster matrix multiplication algorithms with reinforcement learning](https://www.nature.com/articles/s41586-022-05172-4) 
  - [Code](https://github.com/deepmind/alphatensor)
- [2022 MuZero with Self-competition for Rate Control in VP9 Video Compression](https://arxiv.org/abs/2202.06626)
- [2021 DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning](https://arxiv.org/abs/2106.06135)
- [2019 Combining Planning and Deep Reinforcement Learning in Tactical Decision Making for Autonomous Driving](https://arxiv.org/pdf/1905.02680.pdf)

</details>

### å…¶ä»–è®ºæ–‡

<details closed>
<summary>(ç‚¹å‡»æŸ¥çœ‹æ›´å¤š)</summary>

#### ICML
- [Scalable Safe Policy Improvement via Monte Carlo Tree Search](https://openreview.net/pdf?id=tevbBSzSfK) 2023
  - Alberto Castellini, Federico Bianchi, Edoardo Zorzi, Thiago D. SimÃ£o, Alessandro Farinelli, Matthijs T. J. Spaan
  - Key: safe policy improvement online using a MCTS based strategy, Safe Policy Improvement with Baseline Bootstrapping
  - ExpEnv: Gridworld and SysAdmin
- [Efficient Learning for AlphaZero via Path Consistency](https://proceedings.mlr.press/v162/zhao22h/zhao22h.pdf) 2022
  - Dengwei Zhao, Shikui Tu, Lei Xu
  - Key: limited amount of self-plays,  path consistency (PC) optimality
  - ExpEnv: Go, Othello, Gomoku
- [Visualizing MuZero Models](https://arxiv.org/abs/2102.12924) 2021
  - Joery A. de Vries, Ken S. Voskuil, Thomas M. Moerland, Aske Plaat
  - Key: visualizing the value equivalent dynamics model, action trajectories diverge, two regularization techniques
  - ExpEnv: CartPole and MountainCar.
and internal state transition dynamics,
- [Convex Regularization in Monte-Carlo Tree Search](https://arxiv.org/pdf/2007.00391.pdf) 2021
  - Tuan Dam, Carlo D'Eramo, Jan Peters, Joni Pajarinen
  - Key: entropy-regularization backup operators, regret analysis, Tsallis etropy, 
  - ExpEnv: synthetic tree, Atari
- [Information Particle Filter Tree: An Online Algorithm for POMDPs with Belief-Based Rewards on Continuous Domains](http://proceedings.mlr.press/v119/fischer20a/fischer20a.pdf) 2020
  - Johannes Fischer, Ã–mer Sahin Tas
  - Key: Continuous POMDP, Particle Filter Tree, information-based reward shaping, Information Gathering.
  - ExpEnv: POMDPs.jl framework
  - [Code](https://github.com/johannes-fischer/icml2020_ipft)
- [Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search](http://proceedings.mlr.press/v119/chen20k/chen20k.pdf) 2020
  - Binghong Chen, Chengtao Li, Hanjun Dai, Le Song 
  - Key: chemical retrosynthetic planning, neural-based A*-like algorithm, ANDOR tree
  - ExpEnv: USPTO datasets
  - [Code](https://github.com/binghong-ml/retro_star)
#### ICLR
- [The Update Equivalence Framework for Decision-Time Planning](https://openreview.net/forum?id=JXGph215fL) 2024
  - Samuel Sokota, Gabriele Farina, David J Wu, Hengyuan Hu, Kevin A. Wang, J Zico Kolter, Noam Brown
  - Key: imperfect-information games, search, decision-time planning, update equivalence
  - ExpEnv: Hanabi, 3x3 Abrupt Dark Hex and Phantom Tic-Tac-Toe
- [Efficient Multi-agent Reinforcement Learning by Planning](https://openreview.net/forum?id=CpnKq3UJwp) 2024
  - Qihan Liu, Jianing Ye, Xiaoteng Ma, Jun Yang, Bin Liang, Chongjie Zhang
  - Key: multi-agent reinforcement learning, planning, multi-agent MCTS
  - ExpEnv: SMAC, LunarLander, MuJoCo, and Google Research Football
- [Become a Proficient Player with Limited Data through Watching Pure Videos](https://openreview.net/pdf?id=Sy-o2N0hF4f) 2023
  - Weirui Ye, Yunsheng Zhang, Pieter Abbeel, Yang Gao
  - Key: pre-training from action-free videos, forward-inverse cycle consistency (FICC) objective based on vector quantization, pre-training phase, fine-tuning phase.
  - ExpEnv: Atari
- [Policy-Based Self-Competition for Planning Problems](https://arxiv.org/abs/2306.04403) 2023
  - Jonathan Pirnay, Quirin GÃ¶ttl, Jakob Burger, Dominik Gerhard Grimm
  - Key: self-competition, find strong trajectories by planning against possible strategies of its past self.
  - ExpEnv: Traveling Salesman Problem and the Job-Shop Scheduling Problem.
- [Explaining Temporal Graph Models through an Explorer-Navigator Framework](https://openreview.net/pdf?id=BR_ZhvcYbGJ) 2023
  - Wenwen Xia, Mincai Lai, Caihua Shan, Yao Zhang, Xinnan Dai, Xiang Li, Dongsheng Li
  - Key: Temporal GNN Explainer, an explorer to find the event subsets with MCTS, a navigator that learns the correlations between events and helps reduce the search space.
  - ExpEnv: Wikipedia and Reddit, Synthetic datasets
- [SpeedyZero: Mastering Atari with Limited Data and Time](https://openreview.net/pdf?id=Mg5CLXZgvLJ) 2023
  - Yixuan Mei, Jiaxuan Gao, Weirui Ye, Shaohuai Liu, Yang Gao, Yi Wu
  - Key: distributed RL system, Priority Refresh, Clipped LARS
  - ExpEnv: Atari
- [Efficient Offline Policy Optimization with a Learned Model](https://openreview.net/pdf?id=Yt-yM-JbYFO) 2023
  - Zichen Liu, Siyi Li, Wee Sun Lee, Shuicheng YAN, Zhongwen Xu
  - Key: Regularized One-Step Model-based algorithm for Offline-RL
  - ExpEnv: Atariï¼ŒBSuite
  - [Code](https://github.com/sail-sg/rosmo/tree/main)
- [Enabling Arbitrary Translation Objectives with Adaptive Tree Search](https://arxiv.org/pdf/2202.11444.pdf) 2022
  - Wang Ling, Wojciech Stokowiec, Domenic Donato, Chris Dyer, Lei Yu, Laurent Sartran, Austin Matthews
  - Key: adaptive tree search, translation models, autoregressive models, 
  - ExpEnv: Chineseâ€“English and Pashtoâ€“English tasks from WMT2020, Germanâ€“English from WMT2014
- [What's Wrong with Deep Learning in Tree Search for Combinatorial Optimization](https://arxiv.org/abs/2201.10494) 2022
  - Maximili1an BÃ¶ther, Otto KiÃŸig, Martin Taraz, Sarel Cohen, Karen Seidel, Tobias Friedrich
  - Key: Combinatorial optimization, open-source benchmark suite for the NP-hard MAXIMUM INDEPENDENT SET problem, an in-depth analysis of the popular guided tree search algorithm,  compare the tree search implementations to other solvers
  - ExpEnv: NP-hard MAXIMUM INDEPENDENT SET.
  - [Code](https://github.com/maxiboether/mis-benchmark-framework)
- [Monte-Carlo Planning and Learning with Language Action Value Estimates](https://openreview.net/pdf?id=7_G8JySGecm) 2021
  - Youngsoo Jang, Seokin Seo, Jongmin Lee, Kee-Eung Kim
  - Key: Monte-Carlo tree search with language-driven exploration, locally optimistic language value estimates,
  - ExpEnv: Interactive Fiction (IF) games
- [Practical Massively Parallel Monte-Carlo Tree Search Applied to Molecular Design](https://arxiv.org/abs/2006.10504) 2021
  - Xiufeng Yang, Tanuj Kr Aasawat, Kazuki Yoshizoe
  - Key: massively parallel Monte-Carlo Tree Search, molecular design, Hash-driven parallel search, 
  - ExpEnv:  octanol-water partition coefficient (logP) penalized by the synthetic accessibility (SA) and large Ring Penalty score.
- [Watch the Unobserved: A Simple Approach to Parallelizing Monte Carlo Tree Search](https://arxiv.org/pdf/1810.11755.pdf) 2020
  - Anji Liu, Jianshu Chen, Mingze Yu, Yu Zhai, Xuewen Zhou, Ji Liu
  - Key: parallel Monte-Carlo Tree Search, partition the tree into sub-trees efficiently, compare the observation ratio of each processor
  - ExpEnv: speedup and performance comparison on JOY-CITY game, average episode return on atari game
  - [Code](https://github.com/liuanji/WU-UCT)
- [Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees](https://openreview.net/pdf?id=rJgJDAVKvB) 2020
  - Binghong Chen, Bo Dai, Qinjie Lin, Guo Ye, Han Liu, Le Song
  - Key: meta path planning algorithm, exploits a novel neural architecture which can learn promising search directions from problem structures.
  - ExpEnv: a 2d workspace with a 2 DoF (degrees of freedom) point robot, a 3 DoF stick robot and a 5 DoF snake robot
#### NeurIPS

- [LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios](https://openreview.net/pdf?id=oIUXpBnyjv) 2023
  - Yazhe Niu, Yuan Pu, Zhenjie Yang, Xueyan Li, Tong Zhou, Jiyuan Ren, Shuai Hu, Hongsheng Li, Yu Liu
  - Key: the first unified benchmark for deploying MCTS/MuZero in general sequential decision scenarios.
  - ExpEnv: ClassicControl, Box2D, Atari, MuJoCo, GoBigger, MiniGrid, TicTacToe, ConnectFour, Gomoku, 2048, etc.
- [Large Language Models as Commonsense Knowledge for Large-Scale Task Planning](https://openreview.net/pdf?id=Wjp1AYB8lH) 2023
  - Zirui Zhao, Wee Sun Lee, David Hsu
  - Key: world model (LLM) and the LLM-induced policy can be combined in MCTS, to scale up task planning.
  - ExpEnv: multiplication, travel planning, object rearrangement
- [Monte Carlo Tree Search with Boltzmann Exploration](https://openreview.net/pdf?id=NG4DaApavi) 2023
  - Michael Painter, Mohamed Baioumy, Nick Hawes, Bruno Lacerda
  - Key: Boltzmann exploration with MCTS, optimal actions for the maximum entropy objective do not necessarily correspond to optimal actions for the original objective, two improved algorithms.
  - ExpEnv: the Frozen Lake environment, the Sailing Problem, Go
- [Generalized Weighted Path Consistency for Mastering Atari Games](https://openreview.net/pdf?id=vHRLS8HhK1) 2023
  - Dengwei Zhao, Shikui Tu, Lei Xu
  - Key: Generalized Weighted Path Consistency, A weighting mechanism.
  - ExpEnv: Atari
- [Accelerating Monte Carlo Tree Search with Probability Tree State Abstraction](https://openreview.net/pdf?id=0zeLTZAqaJ) 2023
  - Yangqing Fu, Ming Sun, Buqing Nie, Yue Gao
  - Key: probability tree state abstraction, transitivity and aggregation error bound
  - ExpEnv: Atari, CartPole, LunarLander, Gomoku
- [Planning for Sample Efficient Imitation Learning](https://openreview.net/forum?id=BkN5UoAqF7) 2022
  - Zhao-Heng Yin, Weirui Ye, Qifeng Chen, Yang Gao
  - Key: Behavioral Cloningï¼ŒAdversarial Imitation Learning (AIL)ï¼ŒMCTS-based RLï¼Œ
  - ExpEnv: DeepMind Control Suite
  - [Code](https://github.com/zhaohengyin/EfficientImitate)
- [Evaluation Beyond Task Performance: Analyzing Concepts in AlphaZero in Hex](https://openreview.net/pdf?id=dwKwB2Cd-Km) 2022 
  - Charles Lovering, Jessica Zosa Forde, George Konidaris, Ellie Pavlick, Michael L. Littman
  - Key: AlphaZeroâ€™s internal representations, model probing and behavioral tests, how these concepts are captured in the network.
  - ExpEnv: Hex
- [Are AlphaZero-like Agents Robust to Adversarial Perturbations?](https://openreview.net/pdf?id=yZ_JlZaOCzv) 2022
  - Li-Cheng Lan, Huan Zhang, Ti-Rong Wu, Meng-Yu Tsai, I-Chen Wu, 4 Cho-Jui Hsieh
  - Key:  adversarial states, first adversarial attack on Go AIs
  - ExpEnv: Go
- [Monte Carlo Tree Descent for Black-Box Optimization](https://openreview.net/pdf?id=FzdmrTUyZ4g) 2022
  - Yaoguang Zhai, Sicun Gao
  - Key: Black-Box Optimization, how to further integrate samplebased descent for faster optimization. 
  - ExpEnv: synthetic functions for nonlinear optimization, reinforcement learning problems in MuJoCo locomotion environments, and optimization problems in Neural Architecture Search (NAS).
- [Monte Carlo Tree Search based Variable Selection for High Dimensional Bayesian Optimization](https://openreview.net/pdf?id=SUzPos_pUC) 2022
  - Lei Songâˆ— , Ke Xueâˆ— , Xiaobin Huang, Chao Qian
  - Key:  a low-dimensional subspace via MCTS, optimizes in the subspace with any Bayesian optimization algorithm.
  - ExpEnv: NAS-bench problems and MuJoCo locomotion
- [Monte Carlo Tree Search With Iteratively Refining State Abstractions](https://proceedings.neurips.cc/paper/2021/file/9b0ead00a217ea2c12e06a72eec4923f-Paper.pdf) 2021
  - Samuel Sokota, Caleb Ho, Zaheen Ahmad, J. Zico Kolter
  - Key: stochastic environments, Progressive widening, abstraction refining,
  - ExpEnv:  Blackjack, Trap, five by five Go.
- [Deep Synoptic Monte Carlo Planning in Reconnaissance Blind Chess](https://proceedings.neurips.cc/paper/2021/file/215a71a12769b056c3c32e7299f1c5ed-Paper.pdf) 2021
  - Gregory Clark
  - Key: imperfect information, belief state with an unweighted particle filter, a novel stochastic abstraction of information states.
  - ExpEnv:  reconnaissance blind chess
- [POLY-HOOT: Monte-Carlo Planning in Continuous Space MDPs with Non-Asymptotic Analysis](https://proceedings.neurips.cc/paper/2020/file/30de24287a6d8f07b37c716ad51623a7-Paper.pdf) 2020
  - Weichao Mao, Kaiqing Zhang, Qiaomin Xie, Tamer BaÂ¸sar
  - Key: continuous state-action spaces, Hierarchical Optimistic Optimization,
  - ExpEnv: CartPole, Inverted Pendulum, Swing-up, and LunarLander.
- [Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search](https://proceedings.neurips.cc/paper/2020/file/e2ce14e81dba66dbff9cbc35ecfdb704-Paper.pdf) 2020
  - Linnan Wang, Rodrigo Fonseca, Yuandong Tian
  - Key: learns the partition of the search space using a few samples, a nonlinear decision boundary and learns a local model to pick good candidates.
  - ExpEnv: MuJoCo locomotion tasks, Small-scale Benchmarks, 
- [Mix and Match: An Optimistic Tree-Search Approach for Learning Models from Mixture Distributions](https://arxiv.org/abs/1907.10154) 2020
  - Matthew Faw, Rajat Sen, Karthikeyan Shanmugam, Constantine Caramanis, Sanjay Shakkottai
  - Key: covariate shift problem, Mix&Match combines stochastic gradient descent (SGD) with optimistic tree search and model re-use (evolving partially trained models with samples from different mixture distributions)
  - [Code](https://github.com/matthewfaw/mixnmatch)

#### Other Conference or Journal
- [On Monte Carlo Tree Search and Reinforcement Learning](https://www.jair.org/index.php/jair/article/download/11099/26289/20632) Journal of Artificial Intelligence Research 2017.
- [Sample-Efficient Neural Architecture Search by Learning Actions for Monte Carlo Tree Search](https://arxiv.org/pdf/1906.06832) IEEE Transactions on Pattern Analysis and Machine Intelligence 2022.
</details>

## åé¦ˆæ„è§å’Œè´¡çŒ®
- æœ‰ä»»ä½•ç–‘é—®æˆ–æ„è§éƒ½å¯ä»¥åœ¨ github ä¸Šç›´æ¥ [æå‡º issue](https://github.com/opendilab/LightZero/issues/new/choose)
- æˆ–è€…è”ç³»æˆ‘ä»¬çš„é‚®ç®± (opendilab@pjlab.org.cn)

- æ„Ÿè°¢æ‰€æœ‰çš„åé¦ˆæ„è§ï¼ŒåŒ…æ‹¬å¯¹ç®—æ³•å’Œç³»ç»Ÿè®¾è®¡ã€‚è¿™äº›åé¦ˆæ„è§å’Œå»ºè®®éƒ½ä¼šè®© LightZero å˜å¾—æ›´å¥½ã€‚ 


## å¼•ç”¨

```latex
@misc{lightzero,
      title={LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios},
      author={Yazhe Niu and Yuan Pu and Zhenjie Yang and Xueyan Li and Tong Zhou and Jiyuan Ren and Shuai Hu and Hongsheng Li and Yu Liu},
      year={2023},
      eprint={2310.08348},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```

## è‡´è°¢
æ­¤ç®—æ³•åº“çš„å®ç°éƒ¨åˆ†åŸºäºä»¥ä¸‹ GitHub ä»“åº“ï¼Œéå¸¸æ„Ÿè°¢è¿™äº›å¼€åˆ›æ€§å·¥ä½œï¼š
- https://github.com/opendilab/DI-engine
- https://github.com/deepmind/mctx
- https://github.com/YeWR/EfficientZero
- https://github.com/werner-duvaud/muzero-general

ç‰¹åˆ«æ„Ÿè°¢ä»¥ä¸‹è´¡çŒ®è€… [@PaParaZz1](https://github.com/PaParaZz1), [@karroyan](https://github.com/karroyan), [@nighood](https://github.com/nighood), 
[@jayyoung0802](https://github.com/jayyoung0802), [@timothijoe](https://github.com/timothijoe), [@TuTuHuss](https://github.com/TuTuHuss), [@HarryXuancy](https://github.com/HarryXuancy), [@puyuan1996](https://github.com/puyuan1996), [@HansBug](https://github.com/HansBug) å¯¹æœ¬é¡¹ç›®çš„è´¡çŒ®å’Œæ”¯æŒã€‚

æ„Ÿè°¢æ‰€æœ‰ä¸ºæ­¤é¡¹ç›®åšå‡ºè´¡çŒ®çš„äººï¼š
<a href="https://github.com/opendilab/LightZero/graphs/contributors">
<img src="https://contrib.rocks/image?repo=opendilab/LightZero" />
</a>

## è®¸å¯è¯

æœ¬ä»“åº“ä¸­çš„æ‰€æœ‰ä»£ç éƒ½ç¬¦åˆ [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0)ã€‚

<p align="right">(<a href="#top">å›åˆ°é¡¶éƒ¨</a>)</p>

